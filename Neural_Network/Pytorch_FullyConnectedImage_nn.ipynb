{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PJCEEqch1hbU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# Stage 1: PyTorch Basics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn((3, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCo0Sku71pAv",
        "outputId": "1fca152e-1f41-4b2c-cefa-17000a263020"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2998, -1.7342,  0.7148,  0.0622],\n",
              "        [ 0.1768,  1.7425, -2.2632,  1.0246],\n",
              "        [ 0.0991, -0.4391, -0.9792, -0.9587]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1, 2])\n",
        "b = torch.tensor([3, 4])\n",
        "\n",
        "print(a + b)\n",
        "print(a * b)\n",
        "print(torch.dot(a.float(), b.float()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ-Z3NlXaLJq",
        "outputId": "c1aae173-4da6-458e-8cf5-d93187693fdd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 6])\n",
            "tensor([3, 8])\n",
            "tensor(11.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1, 2, 3])\n",
        "x = x.unsqueeze(0)     # Shape: [1, 3]\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD1FaM7cakV7",
        "outputId": "5c1fd3d5-75b5-4415-f5ed-9cb02fbf4094"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1, 2, 3])\n",
        "x = x.squeeze(0)       # Shape: [3]\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48E3tMdYqiw9",
        "outputId": "589a4bf6-cb21-4031-b8c6-ba846d19530b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ§ª Exercise\n",
        "# Create a 3x3 matrix and compute its transpose\n",
        "\n",
        "# Normalize a tensor to mean=0, std=1\n",
        "\n",
        "x= torch.tensor([[1, 2,3 ], [3, 4, 5], [6, 7, 8]], dtype=torch.float32) # Ensure float type for normalization\n",
        "print(\"Original matrix:\")\n",
        "print(x)\n",
        "\n",
        "print(\"\\nTranspose of the matrix:\")\n",
        "print(x.transpose(0, 1))\n",
        "\n",
        "# Normalize the tensor\n",
        "mean = torch.mean(x)\n",
        "std = torch.std(x)\n",
        "print(mean, std)\n",
        "normalized_x = (x - mean) / std\n",
        "\n",
        "print(\"\\nNormalized tensor (mean=0, std=1):\")\n",
        "print(normalized_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_EYoyY8rIBk",
        "outputId": "682b64b8-7cb0-480e-8ad2-c5025812157d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original matrix:\n",
            "tensor([[1., 2., 3.],\n",
            "        [3., 4., 5.],\n",
            "        [6., 7., 8.]])\n",
            "\n",
            "Transpose of the matrix:\n",
            "tensor([[1., 3., 6.],\n",
            "        [2., 4., 7.],\n",
            "        [3., 5., 8.]])\n",
            "tensor(4.3333) tensor(2.3452)\n",
            "\n",
            "Normalized tensor (mean=0, std=1):\n",
            "tensor([[-1.4213, -0.9949, -0.5685],\n",
            "        [-0.5685, -0.1421,  0.2843],\n",
            "        [ 0.7107,  1.1371,  1.5635]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = torch.tensor([2.0], requires_grad=True)\n",
        "y = x**2 + 3*x + 1\n",
        "y.backward()                    # Compute dy/dx\n",
        "print(x.grad)                   # Gradient: dy/dx at x=2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TN01I42pGaR",
        "outputId": "095c24df-be33-4cb1-baca-d5955cba80f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([7.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''This code uses a PyTorch context manager called torch.no_grad(). Here's what it does:\n",
        "\n",
        "with torch.no_grad():: This line starts a block of code where gradient calculations are disabled.\n",
        "Why disable gradients? When you're training a neural network, PyTorch automatically tracks the operations performed on tensors to compute gradients during the backward pass (used for optimization). However, during inference (when you're just using the trained model to make predictions) or when you're evaluating the model's performance, you don't need to compute gradients. Disabling gradient calculation in these cases offers several benefits:\n",
        "Memory saving: It reduces memory consumption because PyTorch doesn't need to store intermediate values required for gradient computation.\n",
        "Speed improvement: It can speed up computations slightly because the overhead of tracking operations for gradients is removed.\n",
        "y = model(x):\n",
        "Inside the with torch.no_grad():\n",
        " block, this line performs a forward pass through your model using the input x.\n",
        " The result is stored in y. Because this is within the no_grad() context, no gradient information will be tracked for the operations within the model during this forward pass.\n",
        "In summary, with torch.no_grad(): is used to perform operations with tensors without building the computation graph for gradient calculation.\n",
        "This is typically done during inference or evaluation phases of a model.\n",
        "'''\n",
        "# with torch.no_grad():\n",
        "#     y = model(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "PQE9mdKBpVT0",
        "outputId": "26738b96-25fb-492f-ac68-d2965d40c064"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"This code uses a PyTorch context manager called torch.no_grad(). Here's what it does:\\n\\nwith torch.no_grad():: This line starts a block of code where gradient calculations are disabled.\\nWhy disable gradients? When you're training a neural network, PyTorch automatically tracks the operations performed on tensors to compute gradients during the backward pass (used for optimization). However, during inference (when you're just using the trained model to make predictions) or when you're evaluating the model's performance, you don't need to compute gradients. Disabling gradient calculation in these cases offers several benefits:\\nMemory saving: It reduces memory consumption because PyTorch doesn't need to store intermediate values required for gradient computation.\\nSpeed improvement: It can speed up computations slightly because the overhead of tracking operations for gradients is removed.\\ny = model(x): \\nInside the with torch.no_grad():\\n block, this line performs a forward pass through your model using the input x. \\n The result is stored in y. Because this is within the no_grad() context, no gradient information will be tracked for the operations within the model during this forward pass.\\nIn summary, with torch.no_grad(): is used to perform operations with tensors without building the computation graph for gradient calculation. \\nThis is typically done during inference or evaluation phases of a model.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stage 1: PyTorch Basics"
      ],
      "metadata": {
        "id": "E_6xisENpjC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Stage 3: Building Neural Networks\n",
        "import torch.nn as nn\n",
        "class Simple_FCC(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers, output_size):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(3, 1)\n",
        "        print(self.linear)\n",
        "\n",
        "n = Simple_FCC()\n",
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v43um17ZpjvN",
        "outputId": "d07a254a-147e-4187-df1c-bc12223da009"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=3, out_features=1, bias=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Simple_FCC(\n",
              "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(3, 2)\n",
        "        self.linear2 = nn.Linear(2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu(self.linear2(self.linear1(x)))\n",
        "\n",
        "model = SimpleNN()\n",
        "print(model(torch.randn(1, 3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZTUNYAAvthL",
        "outputId": "f074d5c8-9bc8-4c8c-87cb-e6a63adf7735"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn(3, 1, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mST83zts3Puw",
        "outputId": "68221459-b2df-458d-95ed-24fbb80721ba"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.7839,  0.6424,  0.1884]],\n",
              "\n",
              "        [[ 0.4831, -0.5884, -0.9183]],\n",
              "\n",
              "        [[ 0.7919,  1.1880, -0.2667]]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Create some dummy data for demonstration\n",
        "# In a real scenario, you would load your dataset and use a DataLoader\n",
        "# x_dummy = torch.randn(10, 1, 3) # 10 samples, batch size 1, 3 input features\n",
        "# y_dummy = torch.randn(10, 1)   # 10 samples, batch size 1, 1 output feature\n",
        "\n",
        "x_dummy = torch.randn(1000, 1, 3) # 10 samples, batch size 1, 3 input features\n",
        "y_dummy = torch.randn(1000, 1)   # 10 samples, batch size 1, 1 output feature\n",
        "\n",
        "for epoch in range(10):\n",
        "    # Simulate iterating over batches\n",
        "    # In a real scenario, a DataLoader would handle batching\n",
        "    for i in range(x_dummy.size(0)):\n",
        "        x_batch = x_dummy[i].unsqueeze(0) # Get one sample and add a batch dimension\n",
        "        y_batch = y_dummy[i].unsqueeze(0) # Get one target and add a batch dimension\n",
        "\n",
        "        # Forward pass\n",
        "        pred = model(x_batch).squeeze(-1) # Squeeze the output to match the target shape\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(pred, y_batch)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrmP6KiQyAnw",
        "outputId": "f5b3d308-4f51-487c-ab16-9c73590f14a1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.0178\n",
            "Epoch 2, Loss: 0.0178\n",
            "Epoch 3, Loss: 0.0178\n",
            "Epoch 4, Loss: 0.0178\n",
            "Epoch 5, Loss: 0.0178\n",
            "Epoch 6, Loss: 0.0178\n",
            "Epoch 7, Loss: 0.0178\n",
            "Epoch 8, Loss: 0.0178\n",
            "Epoch 9, Loss: 0.0178\n",
            "Epoch 10, Loss: 0.0178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n"
      ],
      "metadata": {
        "id": "QH52zf--7jat"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm  # For nice progress bar!\n",
        "# Load Data\n",
        "train_dataset = datasets.MNIST(\n",
        "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
        ")\n",
        "test_dataset = datasets.MNIST(\n",
        "    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",
        ")\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "kR9-euic3Mvj"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2jidnNH7Lx0",
        "outputId": "7608a616-5e4f-4e83-ac92-cbab0c225d7f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x799560772710>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
        "import torchvision.datasets as datasets  # Standard datasets\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
        "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
        "from torch import nn  # All neural network modules\n",
        "from torch.utils.data import (\n",
        "    DataLoader,\n",
        ")  # Gives easier dataset managment by creating mini batches etc.\n",
        "from tqdm import tqdm  # For nice progress bar!\n",
        "class NN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(NN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 50)\n",
        "        self.fc2 = nn.Linear(50, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 3\n",
        "\n",
        "# Load Data\n",
        "train_dataset = datasets.MNIST(\n",
        "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
        ")\n",
        "test_dataset = datasets.MNIST(\n",
        "    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",
        ")\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Initialize network\n",
        "model = NN(input_size=input_size, num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train Network\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
        "        # Get data to cuda if possible\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # Get to correct shape\n",
        "        data = data.reshape(data.shape[0], -1)\n",
        "\n",
        "        # Forward\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient descent or adam step\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "# Check accuracy on training & test to see how good our model\n",
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "\n",
        "    # We don't need to keep track of gradients here so we wrap it in torch.no_grad()\n",
        "    with torch.no_grad():\n",
        "        # Loop through the data\n",
        "        for x, y in loader:\n",
        "\n",
        "            # Move data to device\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "            # linear fully connected layer 1*28*28 = [batch_size, 784]\n",
        "            # Get to correct shape\n",
        "            x = x.reshape(x.shape[0], -1)\n",
        "\n",
        "            # Forward pass\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "\n",
        "            # Check how many we got correct\n",
        "            num_correct += (predictions == y).sum()\n",
        "\n",
        "            # Keep track of number of samples\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "    model.train()\n",
        "    return num_correct / num_samples\n",
        "\n",
        "\n",
        "# Check accuracy on training & test to see how good our model\n",
        "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\n",
        "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zui0g8Sr7z2-",
        "outputId": "2f550db5-9f56-40e2-ced0-3afb0359172b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 938/938 [00:11<00:00, 82.54it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 938/938 [00:11<00:00, 79.67it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 938/938 [00:11<00:00, 82.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training set: 95.74\n",
            "Accuracy on test set: 95.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zIyZ817r9mFi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}